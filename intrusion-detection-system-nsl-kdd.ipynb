{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3d821",
   "metadata": {},
   "source": [
    "# 2. READ DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "file_path = r\"D:\\pfe_iset\\pfe-script-Principale\\Detection_Intrusin_nsl_kdd - Copie (2)\\data\\KDDTest+.txt\"  \n",
    "df = pd.read_csv(file_path)  \n",
    "\n",
    "# Display the first few rows of the DataFrame  \n",
    "print(df.head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 ADJUST COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "columns = (['duration'\n",
    ",'protocol_type'\n",
    ",'service'\n",
    ",'flag'\n",
    ",'src_bytes'\n",
    ",'dst_bytes'\n",
    ",'land'\n",
    ",'wrong_fragment'\n",
    ",'urgent'\n",
    ",'hot'\n",
    ",'num_failed_logins'\n",
    ",'logged_in'\n",
    ",'num_compromised'\n",
    ",'root_shell'\n",
    ",'su_attempted'\n",
    ",'num_root'\n",
    ",'num_file_creations'\n",
    ",'num_shells'\n",
    ",'num_access_files'\n",
    ",'num_outbound_cmds'\n",
    ",'is_host_login'\n",
    ",'is_guest_login'\n",
    ",'count'\n",
    ",'srv_count'\n",
    ",'serror_rate'\n",
    ",'srv_serror_rate'\n",
    ",'rerror_rate'\n",
    ",'srv_rerror_rate'\n",
    ",'same_srv_rate'\n",
    ",'diff_srv_rate'\n",
    ",'srv_diff_host_rate'\n",
    ",'dst_host_count'\n",
    ",'dst_host_srv_count'\n",
    ",'dst_host_same_srv_rate'\n",
    ",'dst_host_diff_srv_rate'\n",
    ",'dst_host_same_src_port_rate'\n",
    ",'dst_host_srv_diff_host_rate'\n",
    ",'dst_host_serror_rate'\n",
    ",'dst_host_srv_serror_rate'\n",
    ",'dst_host_rerror_rate'\n",
    ",'dst_host_srv_rerror_rate'\n",
    ",'attack'\n",
    ",'level'])\n",
    "\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have the names of the features from the given dataset so i adjust the columns from : https://www.kaggle.com/code/timgoodfellow/nsl-kdd-explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different types of dtypes, we need encoding, doesn't seem like we have null values but we will check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outlier values, but we will check if it's too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset doesn't contain any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#helper function for deeper analysis\n",
    "def unique_values(df, columns):\n",
    "    \"\"\"Prints unique values and their counts for specific columns in the DataFrame.\"\"\"\n",
    "\n",
    "    for column_name in columns:\n",
    "        print(f\"Column: {column_name}\\n{'-'*30}\")\n",
    "        unique_vals = df[column_name].unique()\n",
    "        value_counts = df[column_name].value_counts()\n",
    "        print(f\"Unique Values ({len(unique_vals)}): {unique_vals}\\n\")\n",
    "        print(f\"Value Counts:\\n{value_counts}\\n{'='*40}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = df.select_dtypes(include='object').columns\n",
    "unique_values(df, cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further analysis will be in EDA-VISAULAZTION part about these column's impacts on Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset doesn't contain any duplicated row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "df.plot(kind='box', subplots=True, layout=(8, 5), figsize=(20, 40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no too much outlier to misslead the model so i will not drop the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 CLASSIFY ATTACK OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "attack_n = []\n",
    "for i in df.attack :\n",
    "  if i == 'normal':\n",
    "    attack_n.append(\"normal\")\n",
    "  else:\n",
    "    attack_n.append(\"attack\")\n",
    "df['attack'] = attack_n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df['attack'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. EDA - VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df.hist(bins=43,figsize=(20,30));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General visualization in order to get insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Protocol Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "sns.countplot(x='attack',data=df,hue='protocol_type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Attack Counts over Protocol Types',fontdict={'fontsize':16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# So we can see that most of the attacks are from tcp, then udp, and least attack comes from icmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "df[\"protocol_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Service used general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 8))  # Adjusted figure size\n",
    "ax = sns.countplot(x='service', data=df)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")  # Rotated labels\n",
    "plt.xlabel('Service')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Services')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Services most used in general follows as, http,private,domain_u,smtp, ftp,other.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Service used effect on attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 8))  # Adjusted figure size\n",
    "ax = sns.countplot(x='service', hue='attack', data=df)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")  # Rotated labels\n",
    "plt.xlabel('Service')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Attacks by Service')\n",
    "plt.legend(title='Attack Type')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#we can see that private attacks is most common service "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Kernel Density Estimate (KDE) Plot of Duration by Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.displot(\n",
    "    data=df,\n",
    "    x=\"duration\",\n",
    "    hue=\"flag\",\n",
    "    kind=\"kde\",\n",
    "    height=6,\n",
    "    multiple=\"fill\",\n",
    "    clip=(0, None),\n",
    "    palette=\"ch:rot=-.25,hue=1,light=.75\",\n",
    ")\n",
    "plt.title('Kernel Density Estimate (KDE) Plot of Duration by Flag')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Distribution of Attack Types by Guest Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='is_guest_login', hue='attack', data=df, palette='Set2')\n",
    "plt.xlabel('Is Guest Login')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Attack Types by Guest Login')\n",
    "plt.legend(title='Attack Type')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can clearly say that attacks are comes when guest is not login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = df.select_dtypes(include='object').columns\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "clm=['protocol_type', 'service', 'flag', 'attack']\n",
    "for x in clm:\n",
    "    df[x]=le.fit_transform(df[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 TRAIN-TEST-SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"attack\"], axis=1)\n",
    "y = df[\"attack\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1,random_state=43) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "train_index = X_train.columns\n",
    "train_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = train_index\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "Select_features = SelectKBest(mutual_info_classif, k=30)\n",
    "Select_features.fit(X_train, y_train)\n",
    "train_index[Select_features.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "columns=['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "       'dst_bytes', 'wrong_fragment', 'hot', 'logged_in', 'num_compromised',\n",
    "       'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate']\n",
    "\n",
    "#We will continue our model with top 15 features, because dataset is big enough\n",
    "\n",
    "X_train=X_train[columns]\n",
    "X_test=X_test[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test) # we use only transform in order to prevent data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODEL BUILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "XGBoost_model = XGBClassifier(random_state = 42)\n",
    "Logistic_model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "XGBoost = XGBoost_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "Logistic = Logistic_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#it's a helper function in order to evaluate our model if it's overfit or underfit.\n",
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test_Set\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Train_Set\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "eval_metric(Logistic_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "eval_metric(XGBoost_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that ensemble methods such as xgboost,adaboost,gradientboosts has more accurace scores over logistic regression in bigger datasets.\n",
    "\n",
    "It doesn't neccessary but we will do hyperparameter tuning in order to fit the model with best parameters, i would like to remember that xgboost has cross-validation has itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50,64,100,128],\n",
    "    \"max_depth\": [2, 3, 4,5,6],\n",
    "    \"learning_rate\": [0.01,0,0.03, 0.05, 0.1],\n",
    "    \"subsample\": [0.5, 0.8],\n",
    "    \"colsample_bytree\": [0.5, 0.8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "XGB_model = XGBClassifier(random_state=42) #initialize the model\n",
    "\n",
    "XGB_grid_model = GridSearchCV(XGB_model,\n",
    "                        param_grid,\n",
    "                        scoring=\"f1\",\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "XGB_grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "XGB_grid_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier(\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    n_estimators=128,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "# Fit the classifier to your data\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = XGB_model.predict(X_test)\n",
    "y_pred_proba = XGB_model.predict_proba(X_test)\n",
    "\n",
    "xgb_f1 = f1_score(y_test, y_pred)\n",
    "xgb_recall = recall_score(y_test, y_pred)\n",
    "xgb_auc = roc_auc_score(y_test, y_pred_proba[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "xgb_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_estimator(XGB_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "eval_metric(XGB_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "model = XGB_model\n",
    "model.feature_importances_\n",
    "\n",
    "feats = pd.DataFrame(index=X[columns].columns, data= model.feature_importances_, columns=['XGB_importance'])\n",
    "ada_imp_feats = feats.sort_values(\"XGB_importance\", ascending = False)\n",
    "ada_imp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_string = le.inverse_transform(y_pred)\n",
    "y_pred_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Create the countplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=y_pred_string, palette=\"pastel\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Attack Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Attack Types\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac27f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistre le modèle entraîné  \n",
    "joblib.dump(XGB_model, 'xgb_model.joblib')  \n",
    "print(\"Le modèle a été sauvegardé sous le nom 'xgb_model.joblib'.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f099f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2 : Charger et utiliser le modèle  \n",
    "\n",
    "# Charger le modèle sauvegardé  \n",
    "loaded_model = joblib.load('xgb_model.joblib')  \n",
    "\n",
    "# Utiliser le modèle chargé pour faire des prédictions  \n",
    "predictions = loaded_model.predict(X_test)  \n",
    "\n",
    "# Évaluer les prédictions  \n",
    "accuracy = accuracy_score(y_test, predictions)  \n",
    "print(\"Précision des prédictions :\", accuracy)  \n",
    "print(\"Prédictions :\", predictions)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
